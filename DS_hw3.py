# -*- coding: utf-8 -*-
"""Homework 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YCMv2R_edVXeQMNLVLFLBIUrBwT7ALns
"""

!pip install response
!pip install scrapy
!pip install pandas

import requests
import pandas as pd
import time;
from scrapy.http import TextResponse;

"""#Problem 1"""

URL = "http://books.toscrape.com/"
base_url = "http://books.toscrape.com/"

class Book:
    def __init__(self,URL):
        self.URL = URL
        self.page = requests.get(self.URL)
        self.response = TextResponse(body=self.page.text,url=self.URL,encoding="utf-8")

    def get_next(self):
        next_url = self.response.css("li.next a::attr(href)").extract()
        return next_url

    def get_title(self):
        title = self.response.css('h3 a::attr(title)').extract();
        return title

    def get_rating(self):
        rating = [i.replace("star-rating","") for i in self.response.css("p.star-rating::attr(class)").extract()]
        return rating 

    def get_price(self):
        price = [i.replace('Â£','') for i in self.response.css("p.price_color::text").extract()]
        return price 

    def get_hyperlink_book(self):
         hyperlink_book = [base_url+i for i in self.response.css('h3 a::attr(href)').extract()]
         return hyperlink_book

    def get_hyperlink_image(self):
        hyperlink_image = [base_url+i for i in self.response.css('img.thumbnail::attr(src)').extract()]
        return hyperlink_image

    def get_instock(self):
        in_stock = [i.css("p.instock.availability::text").extract() for i in self.response.css("div.product_price")]
        return in_stock

    def get_genre(self):
        genre = self.response.css('ul.breadcrumb li~li~li>a::text').extract()
        return(genre)

    def get_desc(self):
        description = self.response.xpath('//article/p/text()').extract()
        return description

b = Book(URL)
titles = []
ratings = []
prices = []
book_urls =[]
img_urls =[]
in_stock = []
genres = []
descriptions = []

temp_desc = []

books = []

while True:
    if(b.get_next() == []):
        titles = titles + b.get_title()
        ratings = ratings + b.get_rating()
        prices = prices + b.get_price()
        book_urls = book_urls + b.get_hyperlink_book()
        img_urls = img_urls + b.get_hyperlink_image()
        in_stock = in_stock + b.get_instock()
        break
    else:
        titles = titles + b.get_title()
        ratings = ratings + b.get_rating()
        prices = prices + b.get_price()
        book_urls = book_urls + b.get_hyperlink_book()
        img_urls = img_urls + b.get_hyperlink_image()
        in_stock = in_stock + b.get_instock()
        u = b.get_next()[0].replace('catalogue/','')
        URL = base_url + 'catalogue/' + u
        b = Book(URL)

for i in book_urls:
    if('catalogue/' not in i):
        index = str(i).index(base_url) + len(base_url)
        i = i[:index] + 'catalogue/' + i[index:]
    bk = Book(i)
    genres = genres + bk.get_genre()
    for k in bk.get_desc():
        temp_desc.append(str(k).strip().strip('\n'))

descriptions = [i for i in temp_desc if len(i)>0]

books.append(titles)
books.append(ratings)
books.append(prices)
books.append(book_urls)
books.append(img_urls)
books.append(in_stock)
books.append(genres)
books.append(descriptions)

books = list(map(list, zip(*books)))
books_df = pd.DataFrame(books, columns=['Titles','Ratings','Prices','Book links','Image links','Stock','Genre','Description'])

books_df

from google.colab import files
books_df.to_csv('books.csv')
files.download('books.csv')

price_average = sum(map(float,prices))/len(prices)

#The average price is 35.07
price_average

books_df.sort_values(by = ["Prices"],ascending = False).head(10)

#Looking at the top 10  most expensive books, we can observe that the most expensive one has 'Romance'  genre. However, only one of the top 10 most expensive books is rated 5 stars, therefore there is no exact positive reletionship between the price and the rating.

"""#Problem 2"""

URL = "https://staff.am/en/jobs"
base_url = "https://staff.am"

class Jobs:
    def __init__(self,URL):
        self.URL = URL
        self.page = requests.get(self.URL)
        self.response = TextResponse(body=self.page.text,url=self.URL,encoding="utf-8")

    def get_vacancy(self):
        vacancy = self.response.xpath('//div[@class="job-inner job-item-title"]/p[@class="font_bold"]/text()').extract()
        return vacancy 

    def get_company(self):
        company = self.response.xpath('//div[@class="job-inner job-item-title"]/p[@class="job_list_company_title"]/text()').extract()
        return company

    def get_deadline(self):
        dl1 = self.response.css('div[class="job-inner job-list-deadline"] p::text').extract()
        dl2 = [''.join(x) for x in zip(dl1[0::2], dl1[1::2])]
        del dl2[1::2]
        dl = [i.replace("\n\n", "").replace("\n"," ").strip() for i in dl2]
        return dl 

    def get_location(self):
        location = self.response.xpath('//div[@class="job-inner job-list-deadline"]/p[@class="job_location"]/text()').extract()
        location = [i.replace('\n','').strip() for i in location]
        return location 

    def get_ind_page(self):
        ind_page = [base_url + i for i in self.response.xpath('//div[@class="list-view"]/div/div/a/@href').extract()]
        return ind_page

    def get_next(self):
        next_page = self.response.xpath('//ul[@class="pagination"]/li[@class="next"]/a/@href').extract()
        return next_page

j = Jobs(URL)
vacancies = []
companies = []
deadlines = []
locations = []
ind_pages = []

jobs = []

while True:
    if(j.get_next() == []):
        vacancies = vacancies + j.get_vacancy()
        companies = companies + j.get_company()
        deadlines = deadlines + j.get_deadline()
        locations = locations + j.get_location()
        ind_pages = ind_pages + j.get_ind_page()
        break
    else:
        vacancies = vacancies + j.get_vacancy()
        companies = companies + j.get_company()
        deadlines = deadlines + j.get_deadline()
        locations = locations + j.get_location()
        ind_pages = ind_pages + j.get_ind_page()
        URL = base_url + j.get_next()[0]
        j = Jobs(URL)

locations = [i for i in locations if len(i)>0]

jobs.append(vacancies)
jobs.append(companies)
jobs.append(deadlines)
jobs.append(locations)
jobs.append(ind_pages)

jobs = list(map(list, zip(*jobs)))
jobs_df = pd.DataFrame(jobs, columns=['Vacancies','Companies','Deadlines','Locations','Individual Pages'])

from google.colab import files
jobs_df.to_csv('jobs.csv')
files.download('jobs.csv')

jc = jobs_df['Companies'].value_counts().idxmax()
fr_comp = []
for i in jobs_df['Companies']:
    if(i == jc):
        fr_comp.append(i)

print(jc + "is the most popular company, according to the amount of jobs they have posted. As of now they have posted " + str(len(fr_comp)) + " jobs.")

jt = []
for i in jobs_df['Vacancies']:
    if("Data" in i or "DATA" in i):
        jt.append(i)

print(str(len(jt)) + " jobs have the word 'data' inside")
for i in jt:
    print(i)